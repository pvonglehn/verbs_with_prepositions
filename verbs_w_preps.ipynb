{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Spanish verbs and prepositions\n",
    "\n",
    "### Problem:\n",
    "\n",
    "When learning Spanish, as with many languages, it can be difficult to remember which is the correct \n",
    "preposition to use with a verb. \n",
    "\n",
    "e.g. In the following sentence I might mistakingly say 'enamorado en', instead of 'enamorado de'\n",
    "<br><em>Ernesto se ha enamorado <strong>de</strong> su vecina</em>\n",
    "\n",
    "Sometimes in Spanish there is no preposition after a verb, where in English there would be.\n",
    "<br>e.g. Busco mi cartera. I'm looking <strong>for</strong> my wallet.\n",
    "\n",
    "The only way to get this right is to learn by heart which prepositions go with which verbs and then practice them in context... a lot!\n",
    "\n",
    "### Aim of this project:\n",
    "\n",
    "To facilitate learning Spanish verbs + prepositions by finding a large number of example sentences and turning them into <a href=\"https://apps.ankiweb.net/docs/manual.html#_introduction\">Anki flashcards</a> with <a href=\"https://apps.ankiweb.net/docs/manual.html#cloze-deletion\">cloze deletions</a> for practice.<br>\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The end result is a deck of Anki flashcards\n",
    "\n",
    "The resulting deck, <a href=\"https://github.com/pvonglehn/verbs_with_prepositions/blob/master/verbs_with_prepositions.apkg\">verbs_with_prepositions.apkg</a>, can be found on the github repository for this \n",
    "<a href=\"https://github.com/pvonglehn/verbs_with_prepositions\">project.</a>\n",
    "\n",
    "Anki is a flashcard app that uses active recall testing and spaced repetition to help you learn almost anything very efficiently. \n",
    "\n",
    "The front of the flash card displays a sentence with target verb + preposition to be learned the preposition removed and replaced by a 'cloze deletion'.\n",
    "\n",
    "\n",
    "<img src=\"./anki_card_front.png\">\n",
    "\n",
    "\n",
    "You then have to guess the correct preposition (say it allowed or in your head - you don't type anything into Anki)\n",
    "\n",
    "The back of the card is then displayed showing the full sentence and the English translation\n",
    "\n",
    "\n",
    "<img src=\"./anki_card_back.png\">\n",
    "\n",
    "\n",
    "You are then required to say if you got the answer wrong (again), if you got it correct but it wasn't super easy (good), or if you got it correct and it was easy. How soon you get tested on the card again depends on your response. This is a powerful learning method called <a href=\"https://en.wikipedia.org/wiki/Spaced_repetition\"> spaced repetition learning.</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process:\n",
    "\n",
    "1. Get a database of Spanish sentences with English translations from tatoeba.org\n",
    "2. Get a list of verbs + prepositions to learn from <a href=\"https://www.profedeele.es/activities/grammar/spanish-verbs-with-prepositions-explanation-and-activity/?lang=en\">here</a>\n",
    "3. Get all conjugated forms of each verb by webscraping form an <a href=\" http://www.spanishdict.com/conjugate\">online conjugation website</a>\n",
    "4. Find sentences in the database containing examples of each verb + preposition combination. The requires regular expression searching to allow the verb to appear in any conjugated form (there are over 140 forms for each verb)\n",
    "5. Find the English translations for each Spanish sentence \n",
    "6. Select a sample of example sentences for each each verb + preposition combination using stratified sampling\n",
    "7. Write these samples to a tab seperated file with anki formatting for <a href=\"https://apps.ankiweb.net/docs/manual.html#cloze-deletion\">cloze deletions</a>\n",
    "8. Import the cards into Anki\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resources\n",
    "\n",
    "Database of sentences and translations:\n",
    "https://tatoeba.org/eng\n",
    "\n",
    "Online verb conjugator:\n",
    "http://www.spanishdict.com/conjugate/caerse\n",
    "\n",
    "#### Websites about verbs and prepositions in Spanish:\n",
    "\n",
    "Lesson about verbs + prepositions\n",
    "http://laspreposiciones.com/verbs-and-prepositions.html\n",
    "\n",
    "List of over 100 verbs plus prepositions\n",
    "https://www.profedeele.es/activities/grammar/spanish-verbs-with-prepositions-explanation-and-activity/?lang=en\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### problems to fix:\n",
    "    \n",
    "Solve problems with webscraping with non ascii character ñ e.g. verb soñar\n",
    "\n",
    "Get present participles which weren't available from webscraping\n",
    "\n",
    "Avoid false matches for verbs + prepositions\n",
    "<br> e.g. The sentence:\n",
    "<br><em>El aviso de trabajo solicitaba específicamente a una dama.</em>\n",
    "<br>is not an example of a avisar + a, because 'aviso' in this context is a noun, not a verb, although it is indistinguishable from the first person singular present simple conjugation of avisar.\n",
    "\n",
    "\n",
    "### Features to add/changes to be made/further work\n",
    "\n",
    "Add verbs which are not followed by preposition in Spanish but are in English\n",
    "\n",
    "Try doing this with much larger sentence database/text corpus e.g. opensubtitles.org\n",
    "\n",
    "Get bigger list of verbs plus prepositions:\n",
    "e.g. https://ankiweb.net/shared/info/1879270437\n",
    "\n",
    "Generate my own list of verbs + prepositions by analysing many sentences and finding when a verb is followed by a preposition\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting a database of example sentences:\n",
    "\n",
    "To get my example sentences I'm using Tatoeba, a open collection of sentences and translations in many languages.\n",
    "See: https://tatoeba.org/eng/\n",
    "\n",
    "Another possibility to try is opensubtitles.org\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pv7409/anaconda3/lib/python3.6/site-packages/numpy/lib/arraysetops.py:472: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    }
   ],
   "source": [
    "# Load in the Tatoeba database  into pandas DataFrame\n",
    "# Note: file is actually tab seperated, although named .csv\n",
    "# I haven't uploaded this file to github because it is very large, you will need to download it from:\n",
    "# https://tatoeba.org/eng/downloads\n",
    "df = pd.read_csv(\"sentences_detailed.csv\",sep=\"\\t\",index_col=0,header=None)\n",
    "\n",
    "\n",
    "# This produced a FutureWarning. I'm not sure why this warning occured. Everything has loaded correctly now \n",
    "# but the warning means that if numpy or python is upgraded there could be issues \n",
    "# (This is unlikely to cause problems in my opinion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2345682</th>\n",
       "      <td>deu</td>\n",
       "      <td>Welche Oberschule hast du besucht?</td>\n",
       "      <td>Pfirsichbaeumchen</td>\n",
       "      <td>2013-03-29 15:27:19</td>\n",
       "      <td>2013-03-29 15:27:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>956820</th>\n",
       "      <td>pol</td>\n",
       "      <td>Jeśli pan pozwoli, przeszukamy pański bagaż.</td>\n",
       "      <td>zipangu</td>\n",
       "      <td>2011-06-25 02:31:09</td>\n",
       "      <td>2011-06-25 02:31:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4992498</th>\n",
       "      <td>fin</td>\n",
       "      <td>Tomi teeskenteli sitä, että hän oli Marin ystävä.</td>\n",
       "      <td>tadaa25</td>\n",
       "      <td>2016-03-20 08:00:52</td>\n",
       "      <td>2016-03-20 08:00:52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4359218</th>\n",
       "      <td>hun</td>\n",
       "      <td>A garázs üres volt.</td>\n",
       "      <td>bandeirante</td>\n",
       "      <td>2015-07-11 09:40:53</td>\n",
       "      <td>2015-07-11 09:40:53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375514</th>\n",
       "      <td>ara</td>\n",
       "      <td>مع السلامة!</td>\n",
       "      <td>saeb</td>\n",
       "      <td>2010-04-04 15:56:34</td>\n",
       "      <td>2010-09-13 03:24:52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3059990</th>\n",
       "      <td>deu</td>\n",
       "      <td>Ich soll am Montag nach Boston fahren.</td>\n",
       "      <td>thomasvw</td>\n",
       "      <td>2014-02-21 15:51:33</td>\n",
       "      <td>2014-02-21 15:51:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1118865</th>\n",
       "      <td>eng</td>\n",
       "      <td>She likes birdwatching.</td>\n",
       "      <td>Scriptor</td>\n",
       "      <td>2011-09-21 06:16:17</td>\n",
       "      <td>2013-08-27 08:30:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6565182</th>\n",
       "      <td>rus</td>\n",
       "      <td>Интересно, почему Том не пришёл к Мэри на вече...</td>\n",
       "      <td>marafon</td>\n",
       "      <td>2017-12-21 15:44:38</td>\n",
       "      <td>2017-12-21 15:44:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2482459</th>\n",
       "      <td>fra</td>\n",
       "      <td>J'adore être seul.</td>\n",
       "      <td>sacredceltic</td>\n",
       "      <td>2013-06-06 16:31:34</td>\n",
       "      <td>2013-06-06 16:31:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2580844</th>\n",
       "      <td>spa</td>\n",
       "      <td>¿De qué querías hablar?</td>\n",
       "      <td>hayastan</td>\n",
       "      <td>2013-07-10 02:48:24</td>\n",
       "      <td>2013-07-10 02:48:24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           1                                                  2  \\\n",
       "0                                                                 \n",
       "2345682  deu                 Welche Oberschule hast du besucht?   \n",
       "956820   pol       Jeśli pan pozwoli, przeszukamy pański bagaż.   \n",
       "4992498  fin  Tomi teeskenteli sitä, että hän oli Marin ystävä.   \n",
       "4359218  hun                                A garázs üres volt.   \n",
       "375514   ara                                        مع السلامة!   \n",
       "3059990  deu             Ich soll am Montag nach Boston fahren.   \n",
       "1118865  eng                            She likes birdwatching.   \n",
       "6565182  rus  Интересно, почему Том не пришёл к Мэри на вече...   \n",
       "2482459  fra                                 J'adore être seul.   \n",
       "2580844  spa                            ¿De qué querías hablar?   \n",
       "\n",
       "                         3                    4                    5  \n",
       "0                                                                     \n",
       "2345682  Pfirsichbaeumchen  2013-03-29 15:27:19  2013-03-29 15:27:19  \n",
       "956820             zipangu  2011-06-25 02:31:09  2011-06-25 02:31:09  \n",
       "4992498            tadaa25  2016-03-20 08:00:52  2016-03-20 08:00:52  \n",
       "4359218        bandeirante  2015-07-11 09:40:53  2015-07-11 09:40:53  \n",
       "375514                saeb  2010-04-04 15:56:34  2010-09-13 03:24:52  \n",
       "3059990           thomasvw  2014-02-21 15:51:33  2014-02-21 15:51:33  \n",
       "1118865           Scriptor  2011-09-21 06:16:17  2013-08-27 08:30:46  \n",
       "6565182            marafon  2017-12-21 15:44:38  2017-12-21 15:44:38  \n",
       "2482459       sacredceltic  2013-06-06 16:31:34  2013-06-06 16:31:34  \n",
       "2580844           hayastan  2013-07-10 02:48:24  2013-07-10 02:48:24  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Each row consists of a unique id (on the index), the language, the sentence itself, the user who uploaded \n",
    "# the sentence and the time and data.\n",
    "\n",
    "# Look at a random sample of entries\n",
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the English and Spanish sentences and delete columns I'm not interested in\n",
    "\n",
    "english = df.loc[df[1] == 'eng'].drop([1,3,4,5],axis=1)\n",
    "spanish = df.loc[df[1] == 'spa'].drop([1,3,4,5],axis=1)\n",
    "\n",
    "# Rename the columns to something meaningful\n",
    "english.columns = [\"phrase\"]\n",
    "spanish.columns = [\"phrase\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each sentence in the database has a specific id \n",
    "# Translations of the same sentence each have a unique id for each languages\n",
    "\n",
    "# Here I am creating dictionary 'links' linking the sentence ids with the ids of\n",
    "# the ids of their translations in all other languages\n",
    "\n",
    "links = {}\n",
    "with open(\"links.csv\") as f:\n",
    "    for i, line in enumerate(f):\n",
    "        words = line.split()\n",
    "        a = int(words[0])\n",
    "        b = int(words[1])\n",
    "        if a in links:\n",
    "            links[a].append(b)\n",
    "        else:\n",
    "            links[a] = [b]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get a list of verbs + prepositions to search the database for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in list of verbs and the propositions that go with them\n",
    "# list from https://www.profedeele.es/activities/grammar/spanish-verbs-with-prepositions-explanation-and-activity/?lang=en\n",
    "\n",
    "verbs_preps = pd.read_csv(\"verbs_preps.txt\",sep=\"\\t\",header=None)                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove verbs with ñ because thes non ascii characters have been causing problems with webscraping\n",
    "# Try to resolve this!\n",
    "verbs_preps = verbs_preps.loc[~verbs_preps[0].str.contains(\"ñ\")]\n",
    "\n",
    "# Reindex after deleting rows\n",
    "verbs_preps.index = range(0,len(verbs_preps))\n",
    "\n",
    "# Make everything lower case\n",
    "verbs_preps.iloc[:,0] = verbs_preps.iloc[:,0].str.lower().str.strip()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get all conjugated forms of every verb by webscraping a conjugation site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import beautiful soup for webscraping\n",
    "\n",
    "import bs4 as bs\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary where the key is the infinitive of each verb\n",
    "# and the values are all its conjugated forms.\n",
    "# This will be used to search for sentences containing any conjugated form of a verb.\n",
    "\n",
    "conj_dict = {}\n",
    "no_presPar = []\n",
    "for verb, prep in verbs_preps[[0,1]].values:\n",
    "\n",
    "    # create a temporary list to hold all conjugated verb forms for current verb\n",
    "    mylist = []\n",
    "\n",
    "    # add infinitive\n",
    "    mylist.append(verb)\n",
    "    \n",
    "    # Get all the conjugated forms of the verb by scraping a conjugation website \n",
    "    # using beautiful soup web scraping library\n",
    "    sauce = urllib.request.urlopen(\"http://www.spanishdict.com/conjugate/{}\".format(verb)).read()\n",
    "    soup = bs.BeautifulSoup(sauce,'lxml')\n",
    "    presParticiple = None\n",
    "    \n",
    "    # All verb conjugations are of html class \"vtable-word-text\"\n",
    "    for i in soup.findAll(all, class_=\"vtable-word-text\"):\n",
    "        mylist.append(i.text)\n",
    "\n",
    "    # get present participle if available\n",
    "    for x in mylist:\n",
    "        if x[-3:] == \"ndo\":\n",
    "            presParticiple = x.split()[-1]                    \n",
    "            break\n",
    "\n",
    "    # add the verb forms with reflexive pronoun at the end of the verb  \n",
    "    # in infinitive and gerund form for reflexive verbs only\n",
    "    if verb[-3:] == \"rse\":\n",
    "        for ending in (\"me\",\"te\",\"se\",\"nos\",\"os\"):\n",
    "            mylist.append(verb[:-2]+ending)\n",
    "            if presParticiple is not None:\n",
    "                mylist.append(presParticiple[:-2]+ending)\n",
    "\n",
    "    # Make a note of verbs for which the present participle wasn't available            \n",
    "    if presParticiple is None:\n",
    "        no_presPar.append(verb)\n",
    "\n",
    "    # Add dictionary entry for current verb   \n",
    "    conj_dict[verb] = mylist\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['arrepentirse',\n",
       " 'atreverse',\n",
       " 'despreocuparse',\n",
       " 'desvivirse',\n",
       " 'diplomarse',\n",
       " 'entrometerse',\n",
       " 'fugarse',\n",
       " 'jactarse',\n",
       " 'obstinarse',\n",
       " 'quejarse',\n",
       " 'rebelarse',\n",
       " 'renunciar',\n",
       " 'vanagloriarse']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The following verbs didn't have entries for the gerund \"ando/iendo\" conjugations\n",
    "# These could be added manually or from another source - currently not a priority\n",
    "\n",
    "no_presPar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing dictionary to tab seperated file so I don't need to repeat webscraping in future\n",
    "dict_series = pd.Series(conj_dict)\n",
    "dict_series.to_csv(\"verb_conj_dict.tsv\",sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning up dictionary keys (removing whitespace)\n",
    "del_list = []\n",
    "for key in conj_dict.keys():\n",
    "    if \" \" in key:\n",
    "        del_list.append(key)\n",
    "        conj_dict[key.strip()] = conj_dict[key]\n",
    "\n",
    "for key in del_list:\n",
    "    del conj_dict[key]\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find example sentences for each verb + preposition combination in our sentence database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# This will be our output dataframe\n",
    "df_out = None\n",
    "\n",
    "# Loop over all verb + preposition combinations\n",
    "for verb, prep in verbs_preps[[0,1]].values:\n",
    "    \n",
    "    # Create a regular expression 'verbs' that will match any conjugated form of the current verb\n",
    "    verbs = '|'.join(conj_dict[verb])\n",
    "\n",
    "    # Find sentences with the verb + preposition and create a new DataFrame containing the matches\n",
    "    # Note: the prepositions \"a\" and \"de\" when followed by \"el\", they combine with \"el\"\n",
    "    #       to form \"al\" and \"del\", so we need to account for this in our regex\n",
    "    tmpa = (spanish.loc[ spanish.loc[:,\"phrase\"]\n",
    "                        .str.lower().str.contains(\" (?:{}) (?:{} |{}l )\"\n",
    "                        .format(verbs,prep,prep))].copy()\n",
    "           )\n",
    "    \n",
    "    tmpa['verb_match'] =  tmpa.loc[:,\"phrase\"].str.lower().str.extract(\" ({}) ({} |{}l )\".format(verbs,prep,prep))[0]\n",
    "    tmpa['prep_match'] =  tmpa.loc[:,\"phrase\"].str.lower().str.extract(\" ({}) ({} |{}l )\".format(verbs,prep,prep))[1]\n",
    "    tmpa['verb_prep'] = verb + \" \" + prep\n",
    "\n",
    "    # If first verb set dataframe to equal our temporary frame, else append our temporary frame to the output frame\n",
    "    if df_out is None:\n",
    "        df_out = tmpa\n",
    "    else:\n",
    "        df_out = df_out.append(tmpa)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes on the resulting example sentences\n",
    "\n",
    "We have a total of 5719 output sentences\n",
    "\n",
    "<br>There are examples for 88 verb + preposition combinations, while there should be 97. This means that there were no examples in the database found for 11 verb + preposition combinations (see below for which ones).\n",
    "\n",
    "Some verb + prep combinations had many examples (e.g. the most common, tratar de, had 508 examples)\n",
    "\n",
    "18 verb + prep combinations had fewer than 5 examples\n",
    "\n",
    "### Conclusion: I need to use a bigger sentense database to get enough examples for each case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count          5719\n",
       "unique           88\n",
       "top       tratar de\n",
       "freq            508\n",
       "Name: verb_prep, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_out['verb_prep'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     88.000000\n",
       "mean      64.988636\n",
       "std      104.682167\n",
       "min        1.000000\n",
       "25%        5.750000\n",
       "50%       24.000000\n",
       "75%       72.250000\n",
       "max      508.000000\n",
       "Name: verb_prep, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_out['verb_prep'].value_counts().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tratar de     508\n",
       "jugar a       477\n",
       "hablar de     407\n",
       "pensar en     384\n",
       "confiar en    302\n",
       "Name: verb_prep, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_out['verb_prep'].value_counts().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 18 verb and preposition combinations had between 1 and 5 examples\n",
    "df_out['verb_prep'].value_counts().loc[df_out['verb_prep'].value_counts() < 5].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "desdecirse por\n",
      "desligarse de\n",
      "desposeer de\n",
      "despreocuparse de\n",
      "desvivirse por\n",
      "diplomarse en\n",
      "incomodarse con\n",
      "obstinarse en\n",
      "preferir a\n",
      "rebelarse contra\n",
      "reconciliarse con\n",
      "vanagloriarse de\n"
     ]
    }
   ],
   "source": [
    "# There were no examples in the database of the following verb + preposition combinations:\n",
    "for i in (verbs_preps[0] + \" \" + verbs_preps[1]):\n",
    "    if i not in (df_out['verb_prep'].unique()):\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get English translations for our sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The English translations of each sentence are searched for by looking up the sentence id in the\n",
    "# links dictionary and then seeing if any of the sentence ids in the values of the dictionary\n",
    "# entries correspond to English sentences.\n",
    "# Note: Not all sentences have English translations\n",
    "\n",
    "df_out['eng'] = np.nan\n",
    "for row in df_out.index:\n",
    "    if links.get(row):\n",
    "        for i in links[row]:\n",
    "            if i in english.index:\n",
    "                df_out.loc[row,'eng'] = english.loc[i,\"phrase\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now to select some sentences to make Anki cards with"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to do stratified random sampling i.e. take 5 cards from each group verb + preposition combination \n",
    "<br>Take cards with English translations first\n",
    "<br>If there are not enough cards with English translations, take all English sentences\n",
    "first and then sentences without English translations to bring the total to 5.\n",
    "\n",
    "Note: with current sentence database, some verb + prep combinations have less than 5 total sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will be the output dataframe\n",
    "anki = None\n",
    "\n",
    "# Loop over each verb + preposition pair\n",
    "for verb_prep in df_out['verb_prep'].unique():\n",
    "\n",
    "    # Find examples with and without English translations\n",
    "    with_english = df_out.loc[(df_out[\"verb_prep\"] == verb_prep) & (df_out['eng'].notnull())].copy()\n",
    "    without_english = df_out.loc[(df_out[\"verb_prep\"] == verb_prep) & (df_out['eng'].isnull())].copy()\n",
    "    with_english_count = len(with_english)\n",
    "    without_english_count = len(without_english)\n",
    "    verb_prep_sel = df_out.loc[(df_out[\"verb_prep\"] == verb_prep)].copy()\n",
    "    \n",
    "    # If there are enough English examples, just pick 5 randomly\n",
    "    if with_english_count >= 5:\n",
    "        mysample = with_english.sample(5,random_state=1)\n",
    "    \n",
    "    # If there are fewer than 5 examples with English translation, pick those first (if any) then fill up\n",
    "    # the rest with examples without English translations\n",
    "    elif 0 < with_english_count < 5:\n",
    "        mysample = with_english.copy()\n",
    "        \n",
    "        if with_english_count + without_english_count >= 5:\n",
    "            mysample.append(verb_prep_sel.sample(5 - with_english_count,random_state=1))\n",
    "        else:\n",
    "            mysample.append(without_english[:5 - with_english_count])\n",
    "    else:\n",
    "        mysample = without_english.iloc[:5].copy()\n",
    "\n",
    "    # Create a new columns called 'cloze'. This contains a string in a format that Anki can \n",
    "    # read and create flashcards with\n",
    "    for i in mysample.index:\n",
    "        mysample.loc[i,'cloze'] = (mysample.loc[i,'phrase']\n",
    "                              .replace(mysample.loc[i,'verb_match']+\" \"+\n",
    "                                        mysample.loc[i,'prep_match'],\n",
    "                                        mysample.loc[i,'verb_match']+\" \"+  \n",
    "                                        \"{{c1::\" + mysample.loc[i,'prep_match'] + \"::...\" \"}} \") + \"\\t \"\n",
    "                              )\n",
    "\n",
    "    # If first verb, assign the sample rows to the anki dataframe, otherwise append to it\n",
    "    if anki is None:\n",
    "        anki = mysample\n",
    "    else:\n",
    "        anki = anki.append(mysample)\n",
    "\n",
    "\n",
    "# Write out the cloze deletion string and the English translation to a tab seperated value file\n",
    "anki[['cloze','eng']].to_csv(\"for_anki.tsv\",index=False,sep=\"\\t\",header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for_anki.tsv can now be imported into anki <a href=\"https://apps.ankiweb.net/docs/manual.html#importing\">here's how</a>\n",
    "<br>Make sure you import the cards as cloze deletion cards, with the first field assigned to the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cloze</th>\n",
       "      <th>eng</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>854901</th>\n",
       "      <td>Él me advirtió {{c1::de ::...}} que no cruzara...</td>\n",
       "      <td>He warned me against crossing the road at that...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>854903</th>\n",
       "      <td>En ese momento, él me advirtió {{c1::de ::...}...</td>\n",
       "      <td>He warned me against crossing the road at that...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1642418</th>\n",
       "      <td>Los médicos nos advirtieron {{c1::de ::...}} u...</td>\n",
       "      <td>Doctors warn us of a possible danger.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2963451</th>\n",
       "      <td>Tom abusa {{c1::de ::...}} su autoridad.\\t</td>\n",
       "      <td>Tom abuses his authority.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599334</th>\n",
       "      <td>Los países grandes no deberían abusar {{c1::de...</td>\n",
       "      <td>Large countries shouldn't interfere with small...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     cloze  \\\n",
       "854901   Él me advirtió {{c1::de ::...}} que no cruzara...   \n",
       "854903   En ese momento, él me advirtió {{c1::de ::...}...   \n",
       "1642418  Los médicos nos advirtieron {{c1::de ::...}} u...   \n",
       "2963451        Tom abusa {{c1::de ::...}} su autoridad.\\t    \n",
       "1599334  Los países grandes no deberían abusar {{c1::de...   \n",
       "\n",
       "                                                       eng  \n",
       "854901   He warned me against crossing the road at that...  \n",
       "854903   He warned me against crossing the road at that...  \n",
       "1642418              Doctors warn us of a possible danger.  \n",
       "2963451                          Tom abuses his authority.  \n",
       "1599334  Large countries shouldn't interfere with small...  "
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anki[['cloze','eng']].head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
